================================================================================
        CAMERA PRICE PREDICTOR - PROJECT DOCUMENTATION
================================================================================

==============================================================================
                        HOW TO RUN THE PROJECT
==============================================================================

Step 1: Train the Machine Learning Model
-----------------------------------------
Command:
  C:/xampp/htdocs/Git_hub/Cam-price-predictor/.venv/Scripts/python.exe train_model.py

What it does:
  - Trains the XGBoost model on cameras.csv dataset
  - Saves model files to the models/ folder:
    * camera_price_model.pkl
    * label_encoder.pkl
    * feature_names.pkl

Step 2: Start the Flask Web Server
-----------------------------------
Command:
  C:/xampp/htdocs/Git_hub/Cam-price-predictor/.venv/Scripts/python.exe app.py

What it does:
  - Starts Flask development server
  - Opens on http://127.0.0.1:5000
  - Then open this URL in your web browser


==============================================================================
                    LIBRARIES USED & THEIR PURPOSE
==============================================================================

1. FLASK - Web Framework
------------------------
Import: from flask import Flask, render_template, request, jsonify

Purpose:
  - Creates web server and handles HTTP requests
  - render_template() - Displays HTML pages
  - request - Gets form data from users
  - jsonify() - Sends JSON responses for API endpoints

Key Features:
  - Routing (@app.route decorators)
  - Template rendering (Jinja2)
  - Form data handling
  - RESTful API support


2. PANDAS - Data Manipulation
------------------------------
Import: import pandas as pd

Purpose:
  - Reads CSV files: pd.read_csv()
  - Handles data in tables (DataFrames)
  - Data cleaning and analysis
  - Statistical operations

Common Operations:
  - df.head() - View first rows
  - df.info() - Get dataset info
  - df.describe() - Statistical summary
  - df.isnull().sum() - Check missing values


3. NUMPY - Numerical Computing
-------------------------------
Import: import numpy as np

Purpose:
  - Creates arrays for ML predictions
  - Mathematical operations
  - np.array() - Creates feature arrays for model input
  - Fast numerical computations


4. SCIKIT-LEARN - Machine Learning Library
-------------------------------------------
Imports:
  from sklearn.model_selection import train_test_split
  from sklearn.preprocessing import LabelEncoder
  from xgboost import XGBRegressor
  from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

Components:

  a) LabelEncoder
     - Converts text (brand names) to numbers
     - Example: 'Canon' -> 0, 'Nikon' -> 1, 'Sony' -> 2
     - ML models only understand numbers, not text

  b) XGBRegressor (XGBoost)
     - Gradient boosting algorithm for regression
     - Efficient and often provides strong performance on tabular data
     - Parameters (examples):
       * n_estimators=100 - Number of boosting rounds
       * learning_rate=0.1 - Step size shrinkage
       * max_depth=6 - Maximum tree depth for base learners
       * random_state=42 - Ensures reproducibility

  c) train_test_split
     - Splits data into training & testing sets
     - 80% for training, 20% for testing
     - Prevents overfitting

  d) Evaluation Metrics
     - mean_squared_error - Average squared prediction error
     - r2_score - Coefficient of determination (0-1, higher is better)
     - mean_absolute_error - Average absolute difference


5. PICKLE - Model Serialization
--------------------------------
Import: import pickle

Purpose:
  - Saves trained models to binary files
  - Loads models for making predictions
  - Preserves exact model state

Usage:
  - pickle.dump() - Save object to file
  - pickle.load() - Load object from file


==============================================================================
                    IMPORTANT SYNTAX & CONCEPTS
==============================================================================

1. LABELENCODER - Converting Text to Numbers
---------------------------------------------
Code:
  label_encoder = LabelEncoder()
  df['brand_encoded'] = label_encoder.fit_transform(df['brand'])

Explanation:
  - fit_transform() learns the mapping and transforms in one step
  - Creates new column with encoded values
  - Why? ML models only understand numbers, not text like "Canon", "Nikon"

Example:
  Before: ['Canon', 'Nikon', 'Sony', 'Canon']
  After:  [0, 1, 2, 0]


2. FEATURE MATRIX (X) AND TARGET (Y)
-------------------------------------
Code:
  X = df[['brand_encoded', 'megapixels', 'zoom_optical', ...]]  # Features
  y = df['price']  # Target

Explanation:
  - X contains input features (independent variables)
  - y contains the target to predict (dependent variable)
  - Model learns relationship between X and y


3. TRAIN-TEST SPLIT
--------------------
Code:
  X_train, X_test, y_train, y_test = train_test_split(
      X, y, test_size=0.2, random_state=42
  )

Explanation:
  - test_size=0.2 means 20% data for testing, 80% for training
  - random_state=42 ensures reproducible results
  - Prevents overfitting by testing on unseen data

Why Important:
  - Training data teaches the model
  - Testing data evaluates how well it learned
  - Never test on data used for training!


4. MODEL TRAINING
------------------
Code:
    model = XGBRegressor(
      n_estimators=100,
      learning_rate=0.1,
      max_depth=6,
      random_state=42
    )
    model.fit(X_train, y_train)

Explanation:
  - Creates model instance with parameters
  - fit() trains the model on training data
  - Model learns patterns between features and prices


5. MAKING PREDICTIONS
----------------------
Code:
  features = np.array([[brand, megapixels, zoom, ...]])
  predicted_price = model.predict(features)[0]

Explanation:
  - Create numpy array with same features as training
  - predict() returns array, [0] gets first element
  - Model applies learned patterns to new data


6. FLASK ROUTES - URL Endpoints
--------------------------------
Code:
  @app.route('/')
  def home():
      return render_template('index.html')

  @app.route('/predict', methods=['POST'])
  def predict():
      brand = request.form.get('brand')
      # ... process and predict
      return render_template('result.html', prediction=predicted_price)

Explanation:
  - @app.route() decorator defines URL path
  - methods=['POST'] specifies HTTP method
  - request.form.get() retrieves form data
  - render_template() renders HTML with data


7. JINJA2 TEMPLATE SYNTAX (HTML)
---------------------------------
Code:
  {% for brand in brands %}
      <option value="{{ brand }}">{{ brand }}</option>
  {% endfor %}

  {{ prediction }}

Explanation:
  - {% %} - Control structures (loops, conditions)
  - {{ }} - Variable output
  - Server-side rendering before sending HTML to browser


8. CURRENCY CONVERSION
-----------------------
Code:
  USD_TO_LKR = 300
  predicted_price_lkr = predicted_price * USD_TO_LKR

Explanation:
  - Model trained on USD prices
  - Multiply by conversion rate for display
  - Dataset unchanged, conversion only for output


==============================================================================
                    MODEL EVALUATION METRICS
==============================================================================

1. RMSE (Root Mean Squared Error)
----------------------------------
  - Measures average prediction error
  - In same units as target (Rupees)
  - Lower is better
  - Penalizes large errors more than small ones
  - Example: Rs 92,469 means average error of ~Rs 92k

2. MAE (Mean Absolute Error)
-----------------------------
  - Average absolute difference between predicted and actual
  - More intuitive than RMSE
  - Lower is better
  - Example: Rs 43,704 means average off by ~Rs 44k

3. R² SCORE (Coefficient of Determination)
-------------------------------------------
  - Measures how well model fits data
  - Range: 0 to 1 (0% to 100%)
  - Higher is better
  - Example: 0.8787 = 87.87% of variance explained
  - Means model is 88% accurate


==============================================================================
                        PROJECT STRUCTURE
==============================================================================

Car_Price_Predictor/
│
├── data/
│   └── cameras.csv                 # Dataset (100 camera records)
│
├── models/                         # Saved ML models
│   ├── camera_price_model.pkl      # Trained XGBoost model
│   ├── label_encoder.pkl           # Brand name encoder
│   └── feature_names.pkl           # Feature names for reference
│
├── static/
│   └── css/
│       └── style.css               # Styling (gradients, animations)
│
├── templates/                      # HTML templates
│   ├── index.html                  # Input form page
│   └── result.html                 # Prediction result page
│
├── Procedures/
│   └── procedures.txt              # This documentation file
│
├── .venv/                          # Virtual environment
│
├── train_model.py                  # ML training script
├── app.py                          # Flask web server
├── requirements.txt                # Python dependencies
└── README.md                       # Project overview


==============================================================================
                        DATASET FEATURES
==============================================================================

Input Features (9 features):
1. brand_encoded        - Camera brand (encoded as number)
2. megapixels          - Camera resolution (10-65 MP)
3. zoom_optical        - Optical zoom capability (0-30x)
4. zoom_digital        - Digital zoom capability (0-10x)
5. screen_size         - LCD screen size (2.5-3.5 inches)
6. weight_grams        - Camera weight (200-1000 grams)
7. video_resolution_encoded - Video quality (1080p=0, 4K=1)
8. wifi                - WiFi capability (0=No, 1=Yes)
9. bluetooth           - Bluetooth capability (0=No, 1=Yes)

Target Variable:
- price                - Camera price in USD (original dataset)
                        Converted to LKR for display (1 USD = 300 LKR)


==============================================================================
                    FEATURE IMPORTANCE (FROM MODEL)
==============================================================================

1. megapixels (44%)           - Most important feature
2. video_resolution (26%)     - Second most important
3. weight_grams (15%)         - Third most important
4. zoom_digital (7%)
5. zoom_optical (6%)
6. bluetooth (1%)
7. wifi (0.4%)
8. screen_size (0.3%)
9. brand_encoded (0.3%)

Note: Higher megapixels and 4K video resolution significantly increase price


==============================================================================
                        KEY PYTHON CONCEPTS USED
==============================================================================

1. List Comprehension
   - Creating lists efficiently
   - Example: [x*2 for x in range(10)]

2. Dictionary Usage
   - Storing key-value pairs
   - Example: camera_details = {'brand': 'Canon', 'price': 899}

3. Exception Handling
   - try-except blocks to catch errors
   - Prevents application crashes

4. Function Decorators
   - @app.route() for URL routing
   - Modify function behavior without changing code

5. File I/O
   - Reading CSV files
   - Saving/loading pickle files

6. String Formatting
   - f-strings: f"Price: ${price:.2f}"
   - .format() method

7. NumPy Arrays
   - Multi-dimensional arrays
   - Fast mathematical operations

8. Pandas DataFrames
   - Tabular data structures
   - SQL-like operations on data


==============================================================================
                        TIPS & BEST PRACTICES
==============================================================================

1. Always train model before running Flask app
2. Keep virtual environment activated
3. Don't modify CSV while model is training
4. Check terminal for errors if app doesn't load
5. Use Ctrl+C to stop Flask server
6. Clear browser cache if CSS doesn't update
7. Model accuracy improves with more data
8. Test with realistic camera specifications
9. Retrain model after adding new data
10. Keep backup of trained model files


==============================================================================
                        COMMON ISSUES & SOLUTIONS
==============================================================================

Issue: "Model not found" error
Solution: Run train_model.py first to create model files

Issue: Import errors (red underlines)
Solution: Ensure virtual environment is activated and packages installed

Issue: Page not loading
Solution: Check if Flask server is running on port 5000

Issue: Wrong predictions
Solution: Ensure input values are within training data range

Issue: Server won't start
Solution: Check if another app is using port 5000


==============================================================================
                        FUTURE ENHANCEMENTS
==============================================================================

1. Add more camera brands
2. Include camera type (DSLR, Mirrorless, Compact)
3. Add image sensor size feature
4. Implement model comparison (Random Forest vs XGBoost)
5. Add data visualization charts
6. Create user authentication
7. Store prediction history in database
8. Add price range filtering
9. Implement camera recommendation system
10. Deploy to cloud (Heroku, AWS, Azure)


==============================================================================
                        CONTACT & SUPPORT
==============================================================================

For questions or issues:
- Check this documentation first
- Review error messages in terminal
- Verify all dependencies are installed
- Ensure dataset exists in data/ folder
- Make sure models/ folder has all .pkl files


================================================================================
                            END OF DOCUMENTATION
================================================================================

Conclusion - 
Earlier, in this project there was RandomForestRegressor algorithm. then the difference between predicted price and the actual price was RS.30000 for the final sample prediction. so eventually it was replaced into XGBoost (Gradient Boosting) to make the prediction more effective. so then the difference was RS.306